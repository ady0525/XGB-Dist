{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2519,
     "status": "ok",
     "timestamp": 1679000900759,
     "user": {
      "displayName": "Chaochao Zhou",
      "userId": "12741515649526346331"
     },
     "user_tz": 300
    },
    "id": "YBjFH9TOwNKN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "import os, sys\n",
    "from scipy.stats import norm, skewnorm\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, classification_report, make_scorer, log_loss, roc_auc_score, brier_score_loss\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import gpytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1679000900759,
     "user": {
      "displayName": "Chaochao Zhou",
      "userId": "12741515649526346331"
     },
     "user_tz": 300
    },
    "id": "4T75iIWh6ltm"
   },
   "outputs": [],
   "source": [
    "proj_dir = 'C:/Users/ady05/Desktop/NU/DANA/NVQI/prob_learning_new/'\n",
    "workspace = proj_dir + 'OtherModels/VGP-mrs/'\n",
    "util_dir = proj_dir + 'OtherModels/utils/'\n",
    "data_dir = proj_dir + 'datasets/'\n",
    "proc_dir = proj_dir + 'data processing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1551,
     "status": "ok",
     "timestamp": 1679000902308,
     "user": {
      "displayName": "Chaochao Zhou",
      "userId": "12741515649526346331"
     },
     "user_tz": 300
    },
    "id": "v6207etg7sp6"
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, util_dir)\n",
    "from data_proc import data_proc_mrs6\n",
    "from plot_measures import (\n",
    "    plot_confusion_matrix,\n",
    "    plot_roc,\n",
    "    plot_outcome_prob_relation,\n",
    "    plot_feature_importance\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibD2XywL8SRL"
   },
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 11438,
     "status": "ok",
     "timestamp": 1679000913744,
     "user": {
      "displayName": "Chaochao Zhou",
      "userId": "12741515649526346331"
     },
     "user_tz": 300
    },
    "id": "B0IJE6n38TyV"
   },
   "outputs": [],
   "source": [
    "df_comb = pd.read_excel(proc_dir + 'comb.xlsx')\n",
    "df_num = pd.read_excel(data_dir + 'vargroups_numeric_new.xlsx')\n",
    "df_cat = pd.read_excel(data_dir + 'vargroups_categorical_new.xlsx')\n",
    "\n",
    "groupname = 'group postop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 132,
     "status": "ok",
     "timestamp": 1679000913862,
     "user": {
      "displayName": "Chaochao Zhou",
      "userId": "12741515649526346331"
     },
     "user_tz": 300
    },
    "id": "v7pIeBVE8atd",
    "outputId": "4f70027b-7e2c-4515-eeae-b55c701ec274"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3588, 97), (3588,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data, y_data, num_names, cat_names = data_proc_mrs6(df_comb, df_num, df_cat, groupname)\n",
    "\n",
    "(X_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1679000913863,
     "user": {
      "displayName": "Chaochao Zhou",
      "userId": "12741515649526346331"
     },
     "user_tz": 300
    },
    "id": "vi71KQ7x8wMN",
    "outputId": "a6312348-fa5c-47e9-9a74-dd6cd2f58f03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2870, 97), (2870,), (718, 97), (718,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if hasattr(y_data, \"toarray\"):  # Check if y_data is a sparse matrix\n",
    "    y_data = y_data.toarray().ravel() \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_data, y_data, stratify=y_data, test_size=0.2, random_state=1121218\n",
    ")\n",
    "\n",
    "(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)  # Adjust batch size as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Gaussian Process Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 74.35552058749728\n",
      "Epoch 2/100, Loss: 31.156526311238608\n",
      "Epoch 3/100, Loss: 16.947536744011774\n",
      "Epoch 4/100, Loss: 10.90544121000502\n",
      "Epoch 5/100, Loss: 8.018490770128038\n",
      "Epoch 6/100, Loss: 6.30908252927992\n",
      "Epoch 7/100, Loss: 6.046209637324015\n",
      "Epoch 8/100, Loss: 9.071417432361178\n",
      "Epoch 9/100, Loss: 7.398417451646593\n",
      "Epoch 10/100, Loss: 4.65669682290819\n",
      "Epoch 11/100, Loss: 3.494219117694431\n",
      "Epoch 12/100, Loss: 3.306237554550171\n",
      "Epoch 13/100, Loss: 3.2397720601823594\n",
      "Epoch 14/100, Loss: 3.176507043838501\n",
      "Epoch 15/100, Loss: 3.135657792621189\n",
      "Epoch 16/100, Loss: 3.1030798859066433\n",
      "Epoch 17/100, Loss: 3.0735525925954184\n",
      "Epoch 18/100, Loss: 3.0543382909562853\n",
      "Epoch 19/100, Loss: 3.0203043778737384\n",
      "Epoch 20/100, Loss: 2.9979676829444037\n",
      "Epoch 21/100, Loss: 2.9622657722897\n",
      "Epoch 22/100, Loss: 2.9473155710432266\n",
      "Epoch 23/100, Loss: 2.9407342539893255\n",
      "Epoch 24/100, Loss: 2.9333245701260036\n",
      "Epoch 25/100, Loss: 2.9220375061035155\n",
      "Epoch 26/100, Loss: 2.9164155165354413\n",
      "Epoch 27/100, Loss: 2.9046462535858155\n",
      "Epoch 28/100, Loss: 2.8957561016082765\n",
      "Epoch 29/100, Loss: 2.8867595778571236\n",
      "Epoch 30/100, Loss: 2.880731439590454\n",
      "Epoch 31/100, Loss: 2.861818297704061\n",
      "Epoch 32/100, Loss: 2.8573099189334448\n",
      "Epoch 33/100, Loss: 2.8493529319763184\n",
      "Epoch 34/100, Loss: 2.8458000448015\n",
      "Epoch 35/100, Loss: 2.842390473683675\n",
      "Epoch 36/100, Loss: 2.8365767425960966\n",
      "Epoch 37/100, Loss: 2.833601877424452\n",
      "Epoch 38/100, Loss: 2.828787941402859\n",
      "Epoch 39/100, Loss: 2.8280300935109457\n",
      "Epoch 40/100, Loss: 2.821186145146688\n",
      "Epoch 41/100, Loss: 2.8108498997158473\n",
      "Epoch 42/100, Loss: 2.806345166100396\n",
      "Epoch 43/100, Loss: 2.8034035629696317\n",
      "Epoch 44/100, Loss: 2.8005628956688775\n",
      "Epoch 45/100, Loss: 2.797687594095866\n",
      "Epoch 46/100, Loss: 2.7972548378838433\n",
      "Epoch 47/100, Loss: 2.795295317967733\n",
      "Epoch 48/100, Loss: 2.789177311791314\n",
      "Epoch 49/100, Loss: 2.787765736050076\n",
      "Epoch 50/100, Loss: 2.7860366344451903\n",
      "Epoch 51/100, Loss: 2.7775138907962376\n",
      "Epoch 52/100, Loss: 2.776735533608331\n",
      "Epoch 53/100, Loss: 2.777318244510227\n",
      "Epoch 54/100, Loss: 2.7751018630133735\n",
      "Epoch 55/100, Loss: 2.773625620206197\n",
      "Epoch 56/100, Loss: 2.7721923298305935\n",
      "Epoch 57/100, Loss: 2.7711510949664646\n",
      "Epoch 58/100, Loss: 2.7681364324357776\n",
      "Epoch 59/100, Loss: 2.767206154929267\n",
      "Epoch 60/100, Loss: 2.76743803024292\n",
      "Epoch 61/100, Loss: 2.763853104909261\n",
      "Epoch 62/100, Loss: 2.7620611455705433\n",
      "Epoch 63/100, Loss: 2.7598007784949408\n",
      "Epoch 64/100, Loss: 2.7614115662044947\n",
      "Epoch 65/100, Loss: 2.7590018537309433\n",
      "Epoch 66/100, Loss: 2.759804778628879\n",
      "Epoch 67/100, Loss: 2.7593532138400607\n",
      "Epoch 68/100, Loss: 2.7576199743482803\n",
      "Epoch 69/100, Loss: 2.756165599822998\n",
      "Epoch 70/100, Loss: 2.752537711461385\n",
      "Epoch 71/100, Loss: 2.7532245424058703\n",
      "Epoch 72/100, Loss: 2.752661010954115\n",
      "Epoch 73/100, Loss: 2.750743288464016\n",
      "Epoch 74/100, Loss: 2.7512214713626437\n",
      "Epoch 75/100, Loss: 2.750956254535251\n",
      "Epoch 76/100, Loss: 2.7533897240956624\n",
      "Epoch 77/100, Loss: 2.751859516567654\n",
      "Epoch 78/100, Loss: 2.7482357131110295\n",
      "Epoch 79/100, Loss: 2.750505542755127\n",
      "Epoch 80/100, Loss: 2.7481927394866945\n",
      "Epoch 81/100, Loss: 2.747529231177436\n",
      "Epoch 82/100, Loss: 2.7481639862060545\n",
      "Epoch 83/100, Loss: 2.7451839552985295\n",
      "Epoch 84/100, Loss: 2.747104671266344\n",
      "Epoch 85/100, Loss: 2.7457382784949407\n",
      "Epoch 86/100, Loss: 2.7449019379085966\n",
      "Epoch 87/100, Loss: 2.7456605381435817\n",
      "Epoch 88/100, Loss: 2.745440790388319\n",
      "Epoch 89/100, Loss: 2.746188841925727\n",
      "Epoch 90/100, Loss: 2.744053851233588\n",
      "Epoch 91/100, Loss: 2.7439860079023575\n",
      "Epoch 92/100, Loss: 2.742722929848565\n",
      "Epoch 93/100, Loss: 2.742598221037123\n",
      "Epoch 94/100, Loss: 2.7421436892615425\n",
      "Epoch 95/100, Loss: 2.742274438010322\n",
      "Epoch 96/100, Loss: 2.74291762775845\n",
      "Epoch 97/100, Loss: 2.741634474860297\n",
      "Epoch 98/100, Loss: 2.741333368089464\n",
      "Epoch 99/100, Loss: 2.7443375375535752\n",
      "Epoch 100/100, Loss: 2.7431267473432754\n"
     ]
    }
   ],
   "source": [
    "class VariationalGPModel(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\n",
    "            inducing_points.size(0)\n",
    "        )\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "\n",
    "        self.mean_module = gpytorch.means.LinearMean(input_size=inducing_points.size(1))\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel() + gpytorch.kernels.LinearKernel()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "inducing_points = torch.randn(100, X_train_tensor.shape[1])  \n",
    "model = VariationalGPModel(inducing_points)\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=X_train_tensor.shape[0])\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01) \n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5) \n",
    "\n",
    "epochs = 100\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()  \n",
    "        output = model(X_batch)\n",
    "\n",
    "        loss = -mll(output, y_batch)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()  \n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(train_loader)}')\n",
    "\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    predictions = likelihood(model(X_test_tensor))\n",
    "    mean = predictions.mean.numpy()\n",
    "    variance = predictions.variance.numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_pred, y_test):\n",
    "    return np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "def normal_nll(loc, scale, y_test):\n",
    "    return -norm.logpdf(y_test.flatten(), loc=loc, scale=scale).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9362333525797168\n",
      "1.9067080618768024\n"
     ]
    }
   ],
   "source": [
    "print(root_mean_squared_error(mean, y_test))\n",
    "print(normal_nll(mean, variance**0.5, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMjBdQvPIYIUd96TbolZMTb",
   "mount_file_id": "1ofjnJ-uGtBUkE46wy-450uqdd1h002Ir",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
