{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 2519,
     "status": "ok",
     "timestamp": 1679000900759,
     "user": {
      "displayName": "Chaochao Zhou",
      "userId": "12741515649526346331"
     },
     "user_tz": 300
    },
    "id": "YBjFH9TOwNKN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "import os, sys\n",
    "from scipy.stats import norm, skewnorm\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, classification_report, make_scorer, log_loss, roc_auc_score, brier_score_loss\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import gpytorch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1679000900759,
     "user": {
      "displayName": "Chaochao Zhou",
      "userId": "12741515649526346331"
     },
     "user_tz": 300
    },
    "id": "4T75iIWh6ltm"
   },
   "outputs": [],
   "source": [
    "proj_dir = 'C:/Users/ady05/Desktop/NU/DANA/NVQI/prob_learning_new/'\n",
    "workspace = proj_dir + 'OtherModels/VGP-mrs/'\n",
    "util_dir = proj_dir + 'OtherModels/utils/'\n",
    "data_dir = proj_dir + 'datasets/'\n",
    "proc_dir = proj_dir + 'data processing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1551,
     "status": "ok",
     "timestamp": 1679000902308,
     "user": {
      "displayName": "Chaochao Zhou",
      "userId": "12741515649526346331"
     },
     "user_tz": 300
    },
    "id": "v6207etg7sp6"
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, util_dir)\n",
    "from data_proc import data_proc_mrs6\n",
    "from plot_measures import (\n",
    "    plot_confusion_matrix,\n",
    "    plot_roc,\n",
    "    plot_outcome_prob_relation,\n",
    "    plot_feature_importance\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibD2XywL8SRL"
   },
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 11438,
     "status": "ok",
     "timestamp": 1679000913744,
     "user": {
      "displayName": "Chaochao Zhou",
      "userId": "12741515649526346331"
     },
     "user_tz": 300
    },
    "id": "B0IJE6n38TyV"
   },
   "outputs": [],
   "source": [
    "df_comb = pd.read_excel(proc_dir + 'comb.xlsx')\n",
    "df_num = pd.read_excel(data_dir + 'vargroups_numeric_new.xlsx')\n",
    "df_cat = pd.read_excel(data_dir + 'vargroups_categorical_new.xlsx')\n",
    "\n",
    "groupname = 'group preop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 132,
     "status": "ok",
     "timestamp": 1679000913862,
     "user": {
      "displayName": "Chaochao Zhou",
      "userId": "12741515649526346331"
     },
     "user_tz": 300
    },
    "id": "v7pIeBVE8atd",
    "outputId": "4f70027b-7e2c-4515-eeae-b55c701ec274"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3588, 49), (3588,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data, y_data, num_names, cat_names = data_proc_mrs6(df_comb, df_num, df_cat, groupname)\n",
    "\n",
    "(X_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1679000913863,
     "user": {
      "displayName": "Chaochao Zhou",
      "userId": "12741515649526346331"
     },
     "user_tz": 300
    },
    "id": "vi71KQ7x8wMN",
    "outputId": "a6312348-fa5c-47e9-9a74-dd6cd2f58f03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2870, 49), (2870,), (718, 49), (718,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if hasattr(y_data, \"toarray\"):  # Check if y_data is a sparse matrix\n",
    "    y_data = y_data.toarray().ravel() \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_data, y_data, stratify=y_data, test_size=0.2, random_state=1121218\n",
    ")\n",
    "\n",
    "(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Gaussian Process Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 31.88732689751519\n",
      "Epoch 2/100, Loss: 14.176280636257596\n",
      "Epoch 3/100, Loss: 9.484886614481608\n",
      "Epoch 4/100, Loss: 7.6196936077541775\n",
      "Epoch 5/100, Loss: 6.423051738739014\n",
      "Epoch 6/100, Loss: 5.58819121254815\n",
      "Epoch 7/100, Loss: 4.892146555582682\n",
      "Epoch 8/100, Loss: 4.395546452204386\n",
      "Epoch 9/100, Loss: 4.048344013426039\n",
      "Epoch 10/100, Loss: 3.7959648185306127\n",
      "Epoch 11/100, Loss: 3.6317849106258815\n",
      "Epoch 12/100, Loss: 3.5308952861362033\n",
      "Epoch 13/100, Loss: 3.472759426964654\n",
      "Epoch 14/100, Loss: 3.4177063994937473\n",
      "Epoch 15/100, Loss: 3.3882949458228215\n",
      "Epoch 16/100, Loss: 3.3512854788038466\n",
      "Epoch 17/100, Loss: 3.3158426814609103\n",
      "Epoch 18/100, Loss: 3.2991932921939426\n",
      "Epoch 19/100, Loss: 3.2779065079159206\n",
      "Epoch 20/100, Loss: 3.2510728624131944\n",
      "Epoch 21/100, Loss: 3.2156704160902234\n",
      "Epoch 22/100, Loss: 3.211341444651286\n",
      "Epoch 23/100, Loss: 3.2060899469587536\n",
      "Epoch 24/100, Loss: 3.196282582812839\n",
      "Epoch 25/100, Loss: 3.188019132614136\n",
      "Epoch 26/100, Loss: 3.182340224583944\n",
      "Epoch 27/100, Loss: 3.1807766013675267\n",
      "Epoch 28/100, Loss: 3.1756230301327175\n",
      "Epoch 29/100, Loss: 3.1633948538038466\n",
      "Epoch 30/100, Loss: 3.156872961256239\n",
      "Epoch 31/100, Loss: 3.1448710176679824\n",
      "Epoch 32/100, Loss: 3.138125599755181\n",
      "Epoch 33/100, Loss: 3.133966159820557\n",
      "Epoch 34/100, Loss: 3.1356306076049805\n",
      "Epoch 35/100, Loss: 3.132372495863173\n",
      "Epoch 36/100, Loss: 3.130196115705702\n",
      "Epoch 37/100, Loss: 3.1246098200480144\n",
      "Epoch 38/100, Loss: 3.1236448023054333\n",
      "Epoch 39/100, Loss: 3.119034046596951\n",
      "Epoch 40/100, Loss: 3.118851481543647\n",
      "Epoch 41/100, Loss: 3.106020090315077\n",
      "Epoch 42/100, Loss: 3.1075007332695854\n",
      "Epoch 43/100, Loss: 3.1054965760972766\n",
      "Epoch 44/100, Loss: 3.105941104888916\n",
      "Epoch 45/100, Loss: 3.1040965027279324\n",
      "Epoch 46/100, Loss: 3.1039360152350532\n",
      "Epoch 47/100, Loss: 3.1033812522888184\n",
      "Epoch 48/100, Loss: 3.101244078742133\n",
      "Epoch 49/100, Loss: 3.1012166765001083\n",
      "Epoch 50/100, Loss: 3.098313087887234\n",
      "Epoch 51/100, Loss: 3.094976626502143\n",
      "Epoch 52/100, Loss: 3.091210381189982\n",
      "Epoch 53/100, Loss: 3.0920971552530925\n",
      "Epoch 54/100, Loss: 3.0895345316992864\n",
      "Epoch 55/100, Loss: 3.087475474675496\n",
      "Epoch 56/100, Loss: 3.090405511856079\n",
      "Epoch 57/100, Loss: 3.0886924266815186\n",
      "Epoch 58/100, Loss: 3.0887383619944253\n",
      "Epoch 59/100, Loss: 3.08805562655131\n",
      "Epoch 60/100, Loss: 3.088090679380629\n",
      "Epoch 61/100, Loss: 3.081582217746311\n",
      "Epoch 62/100, Loss: 3.0838559521569144\n",
      "Epoch 63/100, Loss: 3.083513598971897\n",
      "Epoch 64/100, Loss: 3.085598839653863\n",
      "Epoch 65/100, Loss: 3.0828902244567873\n",
      "Epoch 66/100, Loss: 3.0844422075483533\n",
      "Epoch 67/100, Loss: 3.081391387515598\n",
      "Epoch 68/100, Loss: 3.0823636849721274\n",
      "Epoch 69/100, Loss: 3.0799838489956324\n",
      "Epoch 70/100, Loss: 3.0790542231665716\n",
      "Epoch 71/100, Loss: 3.079157426622179\n",
      "Epoch 72/100, Loss: 3.078832170698378\n",
      "Epoch 73/100, Loss: 3.0788397153218585\n",
      "Epoch 74/100, Loss: 3.0807582060496013\n",
      "Epoch 75/100, Loss: 3.077852816051907\n",
      "Epoch 76/100, Loss: 3.0774885018666587\n",
      "Epoch 77/100, Loss: 3.078791867362128\n",
      "Epoch 78/100, Loss: 3.0787885506947834\n",
      "Epoch 79/100, Loss: 3.0773620870378284\n",
      "Epoch 80/100, Loss: 3.0785436418321397\n",
      "Epoch 81/100, Loss: 3.075857236650255\n",
      "Epoch 82/100, Loss: 3.077030981911553\n",
      "Epoch 83/100, Loss: 3.0772841877407497\n",
      "Epoch 84/100, Loss: 3.076643074883355\n",
      "Epoch 85/100, Loss: 3.077229478624132\n",
      "Epoch 86/100, Loss: 3.0758038096957736\n",
      "Epoch 87/100, Loss: 3.076672093073527\n",
      "Epoch 88/100, Loss: 3.0761097113291425\n",
      "Epoch 89/100, Loss: 3.0764176262749565\n",
      "Epoch 90/100, Loss: 3.078044393327501\n",
      "Epoch 91/100, Loss: 3.076359764734904\n",
      "Epoch 92/100, Loss: 3.075046851899889\n",
      "Epoch 93/100, Loss: 3.0757153987884522\n",
      "Epoch 94/100, Loss: 3.0771394199795195\n",
      "Epoch 95/100, Loss: 3.078206385506524\n",
      "Epoch 96/100, Loss: 3.0771020889282226\n",
      "Epoch 97/100, Loss: 3.076763243145413\n",
      "Epoch 98/100, Loss: 3.075935951868693\n",
      "Epoch 99/100, Loss: 3.0760448031955296\n",
      "Epoch 100/100, Loss: 3.078130907482571\n"
     ]
    }
   ],
   "source": [
    "class VariationalGPModel(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\n",
    "            inducing_points.size(0)\n",
    "        )\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "\n",
    "        self.mean_module = gpytorch.means.LinearMean(input_size=inducing_points.size(1))\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel() + gpytorch.kernels.LinearKernel()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "inducing_points = torch.randn(100, X_train_tensor.shape[1])  \n",
    "model = VariationalGPModel(inducing_points)\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=X_train_tensor.shape[0])\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01) \n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)  \n",
    "\n",
    "epochs = 100\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()  # Zero out the gradients\n",
    "        output = model(X_batch)\n",
    "\n",
    "        loss = -mll(output, y_batch)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()  # Update learning rate\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(train_loader)}')\n",
    "\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    predictions = likelihood(model(X_test_tensor))\n",
    "    mean = predictions.mean.numpy()\n",
    "    variance = predictions.variance.numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_pred, y_test):\n",
    "    return np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "def normal_nll(loc, scale, y_test):\n",
    "    return -norm.logpdf(y_test.flatten(), loc=loc, scale=scale).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8144037180436943\n",
      "2.645838014394277\n"
     ]
    }
   ],
   "source": [
    "print(root_mean_squared_error(mean, y_test))\n",
    "print(normal_nll(mean, variance**0.5, y_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMjBdQvPIYIUd96TbolZMTb",
   "mount_file_id": "1ofjnJ-uGtBUkE46wy-450uqdd1h002Ir",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
